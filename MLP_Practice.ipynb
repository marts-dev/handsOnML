{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing MLP with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: 2.9.0\n",
      "Keras: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "print(f'Tensorflow: {tf.__version__}')\n",
    "print(f'Keras: {keras.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x285ddaf4fa0>,\n",
       " <keras.layers.core.dense.Dense at 0x285dda94c40>,\n",
       " <keras.layers.core.dense.Dense at 0x285dda94c70>,\n",
       " <keras.layers.core.dense.Dense at 0x285dda94880>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense\") is hidden_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden_1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01134795, -0.00675106, -0.05229093, ..., -0.00418186,\n",
       "        -0.0598775 ,  0.07106587],\n",
       "       [-0.06409153,  0.06776159, -0.02407165, ...,  0.04460551,\n",
       "         0.01744158,  0.05997975],\n",
       "       [ 0.03930804,  0.04812739, -0.05321988, ...,  0.01309039,\n",
       "        -0.06734356, -0.04260853],\n",
       "       ...,\n",
       "       [ 0.02149198, -0.05270053, -0.03208856, ..., -0.07283658,\n",
       "         0.0736753 , -0.00592466],\n",
       "       [-0.01340818,  0.05039493,  0.01156279, ..., -0.02094003,\n",
       "        -0.01815743, -0.04891075],\n",
       "       [-0.0362381 ,  0.0325959 ,  0.00557808, ..., -0.05187834,\n",
       "        -0.01060393, -0.06449775]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",#keras.optimizers.SGD(lr=0.01)\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7263 - accuracy: 0.7650 - val_loss: 0.5224 - val_accuracy: 0.8214\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4863 - accuracy: 0.8310 - val_loss: 0.4471 - val_accuracy: 0.8506\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4407 - accuracy: 0.8459 - val_loss: 0.4128 - val_accuracy: 0.8580\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4137 - accuracy: 0.8548 - val_loss: 0.4182 - val_accuracy: 0.8520\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3927 - accuracy: 0.8610 - val_loss: 0.3862 - val_accuracy: 0.8664\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3783 - accuracy: 0.8671 - val_loss: 0.3720 - val_accuracy: 0.8748\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3659 - accuracy: 0.8703 - val_loss: 0.3684 - val_accuracy: 0.8702\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3544 - accuracy: 0.8734 - val_loss: 0.3568 - val_accuracy: 0.8796\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3438 - accuracy: 0.8784 - val_loss: 0.3773 - val_accuracy: 0.8660\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3356 - accuracy: 0.8797 - val_loss: 0.3457 - val_accuracy: 0.8790\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3268 - accuracy: 0.8833 - val_loss: 0.3422 - val_accuracy: 0.8822\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3202 - accuracy: 0.8849 - val_loss: 0.3391 - val_accuracy: 0.8806\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3120 - accuracy: 0.8883 - val_loss: 0.3390 - val_accuracy: 0.8820\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3056 - accuracy: 0.8903 - val_loss: 0.3307 - val_accuracy: 0.8838\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2987 - accuracy: 0.8931 - val_loss: 0.3347 - val_accuracy: 0.8848\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2923 - accuracy: 0.8946 - val_loss: 0.3343 - val_accuracy: 0.8816\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2870 - accuracy: 0.8963 - val_loss: 0.3391 - val_accuracy: 0.8812\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2817 - accuracy: 0.8971 - val_loss: 0.3422 - val_accuracy: 0.8774\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2763 - accuracy: 0.8987 - val_loss: 0.3234 - val_accuracy: 0.8828\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2705 - accuracy: 0.9027 - val_loss: 0.3351 - val_accuracy: 0.8782\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2669 - accuracy: 0.9034 - val_loss: 0.3048 - val_accuracy: 0.8922\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2611 - accuracy: 0.9062 - val_loss: 0.3073 - val_accuracy: 0.8916\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2560 - accuracy: 0.9084 - val_loss: 0.3066 - val_accuracy: 0.8870\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2505 - accuracy: 0.9096 - val_loss: 0.3123 - val_accuracy: 0.8892\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2475 - accuracy: 0.9107 - val_loss: 0.3012 - val_accuracy: 0.8940\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2433 - accuracy: 0.9128 - val_loss: 0.2986 - val_accuracy: 0.8932\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2393 - accuracy: 0.9148 - val_loss: 0.2970 - val_accuracy: 0.8936\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2358 - accuracy: 0.9158 - val_loss: 0.2994 - val_accuracy: 0.8918\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9161 - val_loss: 0.3127 - val_accuracy: 0.8866\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2280 - accuracy: 0.9182 - val_loss: 0.3057 - val_accuracy: 0.8918\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df)\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)# set vertical range to [0-1]\n",
    "plt.gca().set_xlim(0, 28)\n",
    "plt.legend(history_df.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Regression MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.6419 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7047 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5977 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5706 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5472 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5288 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5130 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4992 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4875 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4777 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4688 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4615 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4547 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4488 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4435 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4389 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4306 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4273 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4212\n",
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38856643],\n",
       "       [1.6792021 ],\n",
       "       [3.1022794 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 30)           930         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2611 - val_loss: 3.3940\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6580 - val_loss: 0.9360\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5878 - val_loss: 0.5649\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5582 - val_loss: 0.5712\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5347 - val_loss: 0.5045\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5158 - val_loss: 0.4831\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5002 - val_loss: 0.4639\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4876 - val_loss: 0.4638\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4760 - val_loss: 0.4421\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4659 - val_loss: 0.4313\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4577 - val_loss: 0.4345\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4498 - val_loss: 0.4168\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4428 - val_loss: 0.4230\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4366 - val_loss: 0.4047\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4307 - val_loss: 0.4078\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4257 - val_loss: 0.3938\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.3952\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4167 - val_loss: 0.3860\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4121 - val_loss: 0.3827\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4088 - val_loss: 0.4054\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4032\n",
      "1/1 [==============================] - 0s 74ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to send different subsets of input features through the wide or deep paths? We will send 5 features (features 0 to 4), and 6 through the deep path (features 2 to 7). Note that 3 features will go through both (features 2, 3 and 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 30)           930         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            36          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.7643 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7584 - val_loss: 0.6710\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6584 - val_loss: 0.6169\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6023 - val_loss: 0.5710\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5663 - val_loss: 0.5420\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5380 - val_loss: 0.5176\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 0.5065\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5025 - val_loss: 0.4790\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4889 - val_loss: 0.4564\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4781 - val_loss: 0.4451\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4678 - val_loss: 0.4295\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4617 - val_loss: 0.4228\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4563 - val_loss: 0.4181\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4526 - val_loss: 0.4147\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4487 - val_loss: 0.4125\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4453 - val_loss: 0.4095\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4416 - val_loss: 0.4111\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4400 - val_loss: 0.4091\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4369 - val_loss: 0.4097\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4350 - val_loss: 0.4174\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4295\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit([X_train_A, X_train_B], y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an auxiliary output for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 30)           930         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 1)            36          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " aux_output (Dense)             (None, 1)            31          ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.7641 - main_output_loss: 2.2851 - aux_output_loss: 7.0750 - val_loss: 1.8045 - val_main_output_loss: 1.3439 - val_aux_output_loss: 5.9498\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1723 - main_output_loss: 0.8243 - aux_output_loss: 4.3038 - val_loss: 0.9344 - val_main_output_loss: 0.6979 - val_aux_output_loss: 3.0635\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8590 - main_output_loss: 0.6713 - aux_output_loss: 2.5486 - val_loss: 0.7760 - val_main_output_loss: 0.6271 - val_aux_output_loss: 2.1165\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7317 - main_output_loss: 0.6136 - aux_output_loss: 1.7945 - val_loss: 0.6953 - val_main_output_loss: 0.5732 - val_aux_output_loss: 1.7940\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6658 - main_output_loss: 0.5760 - aux_output_loss: 1.4745 - val_loss: 0.6473 - val_main_output_loss: 0.5420 - val_aux_output_loss: 1.5950\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6244 - main_output_loss: 0.5466 - aux_output_loss: 1.3242 - val_loss: 0.6045 - val_main_output_loss: 0.5117 - val_aux_output_loss: 1.4396\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5950 - main_output_loss: 0.5235 - aux_output_loss: 1.2391 - val_loss: 0.5736 - val_main_output_loss: 0.4937 - val_aux_output_loss: 1.2925\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5727 - main_output_loss: 0.5052 - aux_output_loss: 1.1799 - val_loss: 0.5439 - val_main_output_loss: 0.4716 - val_aux_output_loss: 1.1945\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5545 - main_output_loss: 0.4900 - aux_output_loss: 1.1356 - val_loss: 0.5232 - val_main_output_loss: 0.4566 - val_aux_output_loss: 1.1224\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5394 - main_output_loss: 0.4773 - aux_output_loss: 1.0982 - val_loss: 0.5091 - val_main_output_loss: 0.4464 - val_aux_output_loss: 1.0733\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5268 - main_output_loss: 0.4669 - aux_output_loss: 1.0655 - val_loss: 0.4939 - val_main_output_loss: 0.4328 - val_aux_output_loss: 1.0433\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5162 - main_output_loss: 0.4584 - aux_output_loss: 1.0359 - val_loss: 0.4838 - val_main_output_loss: 0.4241 - val_aux_output_loss: 1.0203\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5075 - main_output_loss: 0.4518 - aux_output_loss: 1.0090 - val_loss: 0.4772 - val_main_output_loss: 0.4189 - val_aux_output_loss: 1.0015\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5004 - main_output_loss: 0.4467 - aux_output_loss: 0.9836 - val_loss: 0.4714 - val_main_output_loss: 0.4143 - val_aux_output_loss: 0.9852\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4941 - main_output_loss: 0.4424 - aux_output_loss: 0.9597 - val_loss: 0.4661 - val_main_output_loss: 0.4101 - val_aux_output_loss: 0.9705\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4886 - main_output_loss: 0.4387 - aux_output_loss: 0.9378 - val_loss: 0.4617 - val_main_output_loss: 0.4067 - val_aux_output_loss: 0.9566\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4837 - main_output_loss: 0.4356 - aux_output_loss: 0.9168 - val_loss: 0.4577 - val_main_output_loss: 0.4038 - val_aux_output_loss: 0.9423\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4791 - main_output_loss: 0.4327 - aux_output_loss: 0.8968 - val_loss: 0.4539 - val_main_output_loss: 0.4013 - val_aux_output_loss: 0.9266\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4748 - main_output_loss: 0.4300 - aux_output_loss: 0.8777 - val_loss: 0.4518 - val_main_output_loss: 0.4000 - val_aux_output_loss: 0.9181\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4714 - main_output_loss: 0.4282 - aux_output_loss: 0.8603 - val_loss: 0.4512 - val_main_output_loss: 0.4009 - val_aux_output_loss: 0.9039\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4622 - main_output_loss: 0.4211 - aux_output_loss: 0.8314\n",
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test]\n",
    ")\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test[:3], 'r-')\n",
    "plt.plot(y_pred_main, 'g-')\n",
    "plt.plot(y_pred_aux, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6811 - output_1_loss: 2.3824 - output_2_loss: 5.3690 - val_loss: 4.0827 - val_output_1_loss: 3.6804 - val_output_2_loss: 7.7037\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0888 - output_1_loss: 0.7882 - output_2_loss: 3.7939 - val_loss: 1.8117 - val_output_1_loss: 0.9127 - val_output_2_loss: 9.9026\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8406 - output_1_loss: 0.6446 - output_2_loss: 2.6052 - val_loss: 1.6652 - val_output_1_loss: 0.6103 - val_output_2_loss: 11.1593\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7409 - output_1_loss: 0.5967 - output_2_loss: 2.0386 - val_loss: 1.6267 - val_output_1_loss: 0.5937 - val_output_2_loss: 10.9233\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6847 - output_1_loss: 0.5645 - output_2_loss: 1.7665 - val_loss: 1.4905 - val_output_1_loss: 0.5594 - val_output_2_loss: 9.8712\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6460 - output_1_loss: 0.5383 - output_2_loss: 1.6160 - val_loss: 1.3837 - val_output_1_loss: 0.5811 - val_output_2_loss: 8.6074\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6166 - output_1_loss: 0.5165 - output_2_loss: 1.5179 - val_loss: 1.2468 - val_output_1_loss: 0.5687 - val_output_2_loss: 7.3498\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5936 - output_1_loss: 0.4991 - output_2_loss: 1.4442 - val_loss: 1.0622 - val_output_1_loss: 0.4948 - val_output_2_loss: 6.1687\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5736 - output_1_loss: 0.4835 - output_2_loss: 1.3850 - val_loss: 0.9588 - val_output_1_loss: 0.4864 - val_output_2_loss: 5.2100\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5576 - output_1_loss: 0.4712 - output_2_loss: 1.3350 - val_loss: 0.8692 - val_output_1_loss: 0.4772 - val_output_2_loss: 4.3979\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5382 - output_1_loss: 0.4546 - output_2_loss: 1.2903\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021CC8D12820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test[:3], 'r-')\n",
    "plt.plot(y_pred_main, 'g-')\n",
    "plt.plot(y_pred_aux, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021CC9EB9A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5400236],\n",
       "       [1.6505971],\n",
       "       [3.0098243]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x21cc9e9c940>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks during Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4110\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4259 - val_loss: 0.3996\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4201 - val_loss: 0.3939\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4154 - val_loss: 0.3889\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4111 - val_loss: 0.3866\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.3860\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.3746\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3976 - val_loss: 0.3723\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.3697\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.3669\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.3661\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.3631\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3660\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.3625\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3810 - val_loss: 0.3592\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.3563\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3766 - val_loss: 0.3535\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.3709\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3732 - val_loss: 0.3512\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3715 - val_loss: 0.3700\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3476\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.3561\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3671 - val_loss: 0.3527\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3658 - val_loss: 0.3701\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3432\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.3592\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3625 - val_loss: 0.3521\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3613 - val_loss: 0.3626\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.3431\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3765\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3374\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3407\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3348\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.3573\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3367\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3530 - val_loss: 0.3425\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3523 - val_loss: 0.3368\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3515 - val_loss: 0.3514\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3426\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3500 - val_loss: 0.3677\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3563\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3481 - val_loss: 0.3455\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3478 - val_loss: 0.3434\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3657\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3287\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3460 - val_loss: 0.3267\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3439\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.3262\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3912\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3439 - val_loss: 0.3275\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3435 - val_loss: 0.3560\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3430 - val_loss: 0.3237\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3242\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3765\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3417 - val_loss: 0.3289\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3410 - val_loss: 0.3501\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.3456\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3446\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3392 - val_loss: 0.3290\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3217\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3387 - val_loss: 0.3352\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3232\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3567\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3374 - val_loss: 0.3256\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3370 - val_loss: 0.3349\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3365 - val_loss: 0.3559\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3361 - val_loss: 0.3583\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3357 - val_loss: 0.3287\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3351 - val_loss: 0.3203\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3841\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3234\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3342 - val_loss: 0.3476\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3408\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3335 - val_loss: 0.3462\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3332 - val_loss: 0.3347\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.3353\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3324 - val_loss: 0.3276\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3167\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3317 - val_loss: 0.3281\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3312 - val_loss: 0.3636\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3310 - val_loss: 0.3175\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3308 - val_loss: 0.3156\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3305 - val_loss: 0.3532\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3299 - val_loss: 0.3256\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3294 - val_loss: 0.3630\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3296 - val_loss: 0.3375\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3291 - val_loss: 0.3212\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3287 - val_loss: 0.3455\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3285 - val_loss: 0.3159\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3281 - val_loss: 0.3407\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3277 - val_loss: 0.3382\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3273 - val_loss: 0.3212\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3310\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/363 [===========================>..] - ETA: 0s - loss: 0.3277\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3302 - val_loss: 0.3559\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2022_09_26-23_05_12'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4318 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4155 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3949 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3924 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3898 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3809 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7d5c288dc2f51fe8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7d5c288dc2f51fe8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2022_09_26-23_05_40'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5530 - val_loss: 302.8466\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 63.6669 - val_loss: 0.9735\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9411 - val_loss: 0.9599\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9197 - val_loss: 0.8464\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9819 - val_loss: 0.9281\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9240 - val_loss: 0.9089\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9179 - val_loss: 0.8815\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8950 - val_loss: 0.9007\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9150 - val_loss: 0.8734\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8921 - val_loss: 0.8507\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9377 - val_loss: 0.8663\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8821 - val_loss: 0.8661\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8820 - val_loss: 0.8442\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8723 - val_loss: 0.8376\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0060 - val_loss: 0.8278\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0323 - val_loss: 0.8264\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8477 - val_loss: 0.8303\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8441 - val_loss: 0.8028\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8270 - val_loss: 0.8049\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8190 - val_loss: 0.7881\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8061 - val_loss: 0.8479\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7955 - val_loss: 0.7850\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7825 - val_loss: 0.7543\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7755 - val_loss: 0.7205\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7554 - val_loss: 0.8237\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8110 - val_loss: 0.7646\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7860 - val_loss: 0.7630\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7753 - val_loss: 0.7558\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7526 - val_loss: 2.6873\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7860 - val_loss: 0.7643\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step/100), step=step)\n",
    "\n",
    "        data = (np.random.rand(100 + 2) * step / 100)#random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "\n",
    "        images = (np.random.rand(2, 32, 32, 3))#random 32x32 RGB image\n",
    "        tf.summary.image(\"my_image\", images * step / 1000, step=step)\n",
    "\n",
    "        texts = [f\"The step is {str(step)}\", f\"Its square is {str(step**2)}\"]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a `KerasRegressor` based on the `build_model()` function.\n",
    "`KerasRegressor` is a thin wrapper around the Keras model built using `build_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arrog\\AppData\\Local\\Temp\\ipykernel_10988\\1709004121.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1199 - val_loss: 10.5492\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6678 - val_loss: 0.5672\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5200 - val_loss: 0.4875\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4855 - val_loss: 0.4654\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4632 - val_loss: 0.4563\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4478 - val_loss: 0.4691\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4367 - val_loss: 0.4507\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4288 - val_loss: 0.4346\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4220 - val_loss: 0.4450\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4169 - val_loss: 0.4676\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4133 - val_loss: 0.4191\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4093 - val_loss: 0.4730\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4062 - val_loss: 0.4531\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.4157\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4005 - val_loss: 0.4239\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.4113\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.4587\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3939 - val_loss: 0.4396\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3913 - val_loss: 0.4269\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.4792\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3881 - val_loss: 0.4489\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3865 - val_loss: 0.4685\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3848 - val_loss: 0.3778\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.4161\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.4650\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3804 - val_loss: 0.4595\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3796 - val_loss: 0.3705\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3782 - val_loss: 0.4312\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.3977\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4618\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.4339\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.4634\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3736\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3711 - val_loss: 0.3775\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3705 - val_loss: 0.4735\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3697 - val_loss: 0.3513\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.4120\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3616\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3668 - val_loss: 0.3634\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3656 - val_loss: 0.4097\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3655 - val_loss: 0.4119\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.4322\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.4297\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3622 - val_loss: 0.4451\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3622 - val_loss: 0.3515\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.3710\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3634\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test[:3], 'r-')\n",
    "plt.plot(y_pred, 'g-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1876 - val_loss: 4.8718\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6812 - val_loss: 0.8878\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5682 - val_loss: 0.5266\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5155 - val_loss: 0.4779\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4749 - val_loss: 0.4461\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4433 - val_loss: 0.4618\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4211 - val_loss: 0.4105\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4046 - val_loss: 0.4408\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4375\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3854 - val_loss: 0.4253\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.3944\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.3875\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3672 - val_loss: 0.4042\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3641 - val_loss: 0.4090\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3599 - val_loss: 0.3954\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3571 - val_loss: 0.4022\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3539 - val_loss: 0.3989\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3517 - val_loss: 0.3967\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3482 - val_loss: 0.3900\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3467 - val_loss: 0.3891\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3945\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3878\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3676\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4606 - val_loss: 3.3926\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6127 - val_loss: 1.3051\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5283 - val_loss: 0.9746\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4769 - val_loss: 0.7075\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4449 - val_loss: 0.5758\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4252 - val_loss: 0.5776\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4120 - val_loss: 0.5693\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.5646\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3917 - val_loss: 0.6694\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3850 - val_loss: 0.6763\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3786 - val_loss: 0.6887\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.6803\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3695 - val_loss: 0.7331\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3663 - val_loss: 0.8604\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3627 - val_loss: 0.8496\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 0.8372\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.8858\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3541 - val_loss: 0.9050\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3762\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3314 - val_loss: 2.1251\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6371 - val_loss: 0.6652\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5385 - val_loss: 0.5186\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4921 - val_loss: 0.5057\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4605 - val_loss: 0.4539\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.4727\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.4347\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.4347\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4033 - val_loss: 0.4615\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.3928\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4783\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3870 - val_loss: 0.4082\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.3872\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.4671\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3761 - val_loss: 0.3635\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3714 - val_loss: 0.4410\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3686 - val_loss: 0.3700\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3654 - val_loss: 0.3925\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.4356\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3988\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.3829\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3561 - val_loss: 0.3659\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3541 - val_loss: 0.3470\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.4235\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3513 - val_loss: 0.3387\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3619\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.4402\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3459 - val_loss: 0.3354\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3440 - val_loss: 0.4613\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3435 - val_loss: 0.3748\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3712\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.4152\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3378 - val_loss: 0.4083\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3363 - val_loss: 0.3750\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3356 - val_loss: 0.3305\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.4289\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3333 - val_loss: 0.3676\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.4943\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3314 - val_loss: 0.3215\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.4265\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3272 - val_loss: 0.4025\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3261 - val_loss: 0.4231\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3445\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3246 - val_loss: 0.4308\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3384\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3218 - val_loss: 0.4474\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3206 - val_loss: 0.3458\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3214 - val_loss: 0.3557\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3184 - val_loss: 0.4319\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3316\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6.8031 - val_loss: 36.5226\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.8566 - val_loss: 21.7926\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.5502 - val_loss: 13.0438\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.6634 - val_loss: 7.8686\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0538 - val_loss: 4.8146\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6310 - val_loss: 2.9900\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3351 - val_loss: 1.9337\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1264 - val_loss: 1.3295\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9782 - val_loss: 1.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8720 - val_loss: 0.8122\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7952 - val_loss: 0.7184\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7394 - val_loss: 0.6768\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6984 - val_loss: 0.6668\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6681 - val_loss: 0.6760\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6456 - val_loss: 0.6843\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.7025\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.7220\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.7442\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5980 - val_loss: 0.7657\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5919 - val_loss: 0.7839\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5872 - val_loss: 0.7848\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 0.8001\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5798 - val_loss: 0.8122\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5765\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6.2271 - val_loss: 32.1350\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.3940 - val_loss: 26.3746\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.1777 - val_loss: 21.8178\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3617 - val_loss: 18.1697\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8089 - val_loss: 15.1865\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 12.7161\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1723 - val_loss: 10.6513\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 8.9049\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8679 - val_loss: 7.4234\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7801 - val_loss: 6.1667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7179 - val_loss: 5.0882\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6734 - val_loss: 4.1707\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6413 - val_loss: 3.3911\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6177 - val_loss: 2.7358\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6001 - val_loss: 2.1852\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5867 - val_loss: 1.7296\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 1.3598\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5683 - val_loss: 1.0660\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - val_loss: 0.8402\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5562 - val_loss: 0.6771\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5516 - val_loss: 0.5687\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5477 - val_loss: 0.5115\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5442 - val_loss: 0.4998\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 0.5293\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5384 - val_loss: 0.5960\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5358 - val_loss: 0.6962\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 0.8270\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 0.9841\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 1.1669\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 1.3717\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.5946\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.8343\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 2.0893\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5598\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.4053 - val_loss: 14.0519\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.9846 - val_loss: 9.0272\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.0215 - val_loss: 6.0449\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3612 - val_loss: 4.2761\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9038 - val_loss: 3.1351\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5840 - val_loss: 2.4355\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3593 - val_loss: 1.9932\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2000 - val_loss: 1.7224\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0863 - val_loss: 1.5233\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0039 - val_loss: 1.3696\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 1.2976\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8992 - val_loss: 1.2271\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8655 - val_loss: 1.1712\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8397 - val_loss: 1.1454\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8194 - val_loss: 1.1159\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8031 - val_loss: 1.1183\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7898 - val_loss: 1.1030\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7785 - val_loss: 1.0886\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7685 - val_loss: 1.1047\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7601 - val_loss: 1.0993\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7522 - val_loss: 1.0943\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7451 - val_loss: 1.0931\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7385 - val_loss: 1.0744\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7322 - val_loss: 1.0674\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7263 - val_loss: 1.0590\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7207 - val_loss: 1.0402\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7151 - val_loss: 1.0632\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7101 - val_loss: 1.0583\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7050 - val_loss: 1.0695\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7003 - val_loss: 1.0625\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6955 - val_loss: 1.0638\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6910 - val_loss: 1.0698\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6865 - val_loss: 1.0731\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6823 - val_loss: 1.0783\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6781 - val_loss: 1.0809\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6742 - val_loss: 1.0510\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6779\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7728 - val_loss: 7.7047\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7276 - val_loss: 3.4474\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5776 - val_loss: 0.5166\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4937 - val_loss: 0.4529\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4557 - val_loss: 0.4270\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4280 - val_loss: 0.4342\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4088 - val_loss: 0.4050\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3956 - val_loss: 0.4366\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.4222\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3785 - val_loss: 0.4162\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.4006\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3668 - val_loss: 0.3795\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3618 - val_loss: 0.4120\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.4275\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.4002\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.4087\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.4150\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3484 - val_loss: 0.3983\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.4130\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3440 - val_loss: 0.4007\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.3968\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3948\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3650\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6397 - val_loss: 4.2754\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6415 - val_loss: 1.3332\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5608 - val_loss: 0.5926\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5107 - val_loss: 0.4838\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4733 - val_loss: 0.5475\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4466 - val_loss: 0.5195\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4270 - val_loss: 0.4760\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.4385\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3975 - val_loss: 0.3735\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3881 - val_loss: 0.3635\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.3876\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3714 - val_loss: 0.4175\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3672 - val_loss: 0.5007\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.6646\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.6879\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3553 - val_loss: 0.7995\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3526 - val_loss: 0.8134\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.9519\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.8823\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3447 - val_loss: 0.8482\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3659\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5480 - val_loss: 1.6023\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6139 - val_loss: 0.5383\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5299 - val_loss: 0.4804\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4836 - val_loss: 0.4704\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4507 - val_loss: 0.4227\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4293 - val_loss: 0.4268\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4145 - val_loss: 0.3899\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4037 - val_loss: 0.3839\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4242\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3899 - val_loss: 0.3621\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.4419\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3796 - val_loss: 0.3809\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.3560\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.4405\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3696 - val_loss: 0.3503\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3656 - val_loss: 0.3818\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3638 - val_loss: 0.3481\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3666\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.3914\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3750\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3549 - val_loss: 0.3466\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3357\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3505 - val_loss: 0.3423\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3607\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3474 - val_loss: 0.3287\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3296\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3432 - val_loss: 0.3913\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.3460\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3912\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3406 - val_loss: 0.3546\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3378 - val_loss: 0.3416\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3365 - val_loss: 0.3724\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3354 - val_loss: 0.3565\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3339 - val_loss: 0.3879\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3341 - val_loss: 0.3208\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3311 - val_loss: 0.3327\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3314 - val_loss: 0.3214\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3305 - val_loss: 0.4319\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3297 - val_loss: 0.3138\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3277 - val_loss: 0.3572\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3259 - val_loss: 0.3661\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3257 - val_loss: 0.3413\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3246 - val_loss: 0.3168\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3233 - val_loss: 0.3396\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3233 - val_loss: 0.3182\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3216 - val_loss: 0.3425\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3203 - val_loss: 0.3203\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3200 - val_loss: 0.3120\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3177 - val_loss: 0.3966\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3178 - val_loss: 0.3186\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3162 - val_loss: 0.3907\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3171 - val_loss: 0.3070\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3154 - val_loss: 0.3068\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3145 - val_loss: 0.3074\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3132 - val_loss: 0.3059\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3112 - val_loss: 0.3192\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3122 - val_loss: 0.3602\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3125 - val_loss: 0.3044\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3102 - val_loss: 0.3616\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3103 - val_loss: 0.3046\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3086 - val_loss: 0.3136\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3073 - val_loss: 0.3244\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3076 - val_loss: 0.3132\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3073 - val_loss: 0.3156\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3066 - val_loss: 0.3679\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3059 - val_loss: 0.3814\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3052 - val_loss: 0.3297\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3040 - val_loss: 0.3516\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3139\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.1111 - val_loss: 5.8867\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2920 - val_loss: 2.9685\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9631 - val_loss: 2.3925\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8560 - val_loss: 1.8069\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7974 - val_loss: 1.4324\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7593 - val_loss: 1.2365\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7324 - val_loss: 1.0518\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7111 - val_loss: 0.9274\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6927 - val_loss: 0.8042\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6764 - val_loss: 0.7307\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6784\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6490 - val_loss: 0.6398\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6367 - val_loss: 0.6182\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6250 - val_loss: 0.6062\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6137 - val_loss: 0.5888\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6024 - val_loss: 0.5767\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5919 - val_loss: 0.5660\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5816 - val_loss: 0.5563\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5714 - val_loss: 0.5485\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5622 - val_loss: 0.5352\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5530 - val_loss: 0.5277\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5438 - val_loss: 0.5179\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5350 - val_loss: 0.5092\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5261 - val_loss: 0.4987\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5182 - val_loss: 0.4926\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5099 - val_loss: 0.4863\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 0.4789\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4948 - val_loss: 0.4763\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.4699\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4809 - val_loss: 0.4643\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4746 - val_loss: 0.4585\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4688 - val_loss: 0.4568\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.4551\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.4532\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.4523\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4498 - val_loss: 0.4509\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4517\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 0.4511\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4514\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4366 - val_loss: 0.4568\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4338 - val_loss: 0.4559\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4551\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4294 - val_loss: 0.4500\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.4630\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4254 - val_loss: 0.4565\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4235 - val_loss: 0.4477\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4221 - val_loss: 0.4551\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4206 - val_loss: 0.4503\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4192 - val_loss: 0.4521\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 0.4526\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4166 - val_loss: 0.4440\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4157 - val_loss: 0.4481\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.4476\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4135 - val_loss: 0.4382\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.4434\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4118 - val_loss: 0.4436\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.4430\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4099 - val_loss: 0.4473\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4092 - val_loss: 0.4407\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4082 - val_loss: 0.4371\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4078 - val_loss: 0.4425\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4071 - val_loss: 0.4419\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4063 - val_loss: 0.4366\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.4464\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4476\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.4391\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4039 - val_loss: 0.4391\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4033 - val_loss: 0.4398\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4027 - val_loss: 0.4396\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4020 - val_loss: 0.4361\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4015 - val_loss: 0.4380\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4009 - val_loss: 0.4392\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.4335\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.4321\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3994 - val_loss: 0.4325\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3986 - val_loss: 0.4332\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4289\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4338\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3973 - val_loss: 0.4317\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3966 - val_loss: 0.4257\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3963 - val_loss: 0.4312\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3960 - val_loss: 0.4337\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.4284\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4350\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3946 - val_loss: 0.4268\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.4339\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3938 - val_loss: 0.4237\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.4181\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.4224\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3923 - val_loss: 0.4307\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3920 - val_loss: 0.4236\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4206\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 0.4231\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4238\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3904 - val_loss: 0.4229\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.4257\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.4168\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3890 - val_loss: 0.4140\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.4324\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.4175\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4130\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.5293 - val_loss: 16.1915\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1058 - val_loss: 12.2310\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8909 - val_loss: 8.1104\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7976 - val_loss: 5.2741\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7443 - val_loss: 3.6009\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7084 - val_loss: 2.5512\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6802 - val_loss: 1.7216\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6561 - val_loss: 1.2068\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6352 - val_loss: 0.9060\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6167 - val_loss: 0.7174\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6000 - val_loss: 0.6133\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5848 - val_loss: 0.5545\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5708 - val_loss: 0.5562\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5586 - val_loss: 0.5656\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5474 - val_loss: 0.6128\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5374 - val_loss: 0.6403\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5284 - val_loss: 0.7000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5202 - val_loss: 0.7323\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5127 - val_loss: 0.8202\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5063 - val_loss: 0.8653\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5003 - val_loss: 0.9552\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4949 - val_loss: 0.9576\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5252\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.0922 - val_loss: 3.2606\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3509 - val_loss: 1.9950\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9603 - val_loss: 1.2025\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8093 - val_loss: 0.8831\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7340 - val_loss: 0.7362\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6937 - val_loss: 0.6873\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6638 - val_loss: 0.6418\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6426 - val_loss: 0.6133\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6232 - val_loss: 0.6017\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6052 - val_loss: 0.5814\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5920 - val_loss: 0.5706\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5779 - val_loss: 0.5614\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5646 - val_loss: 0.5465\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5543 - val_loss: 0.5462\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5436 - val_loss: 0.5340\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5339 - val_loss: 0.5203\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5251 - val_loss: 0.5165\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5170 - val_loss: 0.5082\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5095 - val_loss: 0.4988\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5021 - val_loss: 0.4930\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.4862\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4895 - val_loss: 0.4810\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4838 - val_loss: 0.4796\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.4804\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.4708\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4680 - val_loss: 0.4664\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4635 - val_loss: 0.4623\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4597 - val_loss: 0.4656\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4553 - val_loss: 0.4699\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4524 - val_loss: 0.4684\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4488 - val_loss: 0.4633\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4460 - val_loss: 0.4710\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4428 - val_loss: 0.4650\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4756\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4382 - val_loss: 0.4725\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4355 - val_loss: 0.4663\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4334 - val_loss: 0.4659\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4383\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.7333 - val_loss: 9.3796\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.8915 - val_loss: 6.0344\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7589 - val_loss: 4.0591\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0452 - val_loss: 2.8692\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5862 - val_loss: 2.1384\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2854 - val_loss: 1.7050\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0857 - val_loss: 1.4234\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9513 - val_loss: 1.2415\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8596 - val_loss: 1.1048\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7959 - val_loss: 1.0351\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7514 - val_loss: 0.9926\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7199 - val_loss: 0.9425\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6966 - val_loss: 0.9371\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6798 - val_loss: 0.9399\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6671 - val_loss: 0.9191\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6571 - val_loss: 0.9215\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6491 - val_loss: 0.9250\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6425 - val_loss: 0.9356\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6370 - val_loss: 0.9463\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6323 - val_loss: 0.9531\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6283 - val_loss: 0.9334\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6243 - val_loss: 0.9415\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6209 - val_loss: 0.9460\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6177 - val_loss: 0.9478\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.9378\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6108\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.4969 - val_loss: 40.1535\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.8351 - val_loss: 32.9615\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.7666 - val_loss: 27.2395\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0707 - val_loss: 22.6096\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6119 - val_loss: 18.7981\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3064 - val_loss: 15.6225\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1010 - val_loss: 12.9555\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9615 - val_loss: 10.6970\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8657 - val_loss: 8.7838\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7989 - val_loss: 7.1678\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7516 - val_loss: 5.7921\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7173 - val_loss: 4.6346\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6919 - val_loss: 3.6652\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6726 - val_loss: 2.8670\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6575 - val_loss: 2.2122\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6453 - val_loss: 1.6866\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6351 - val_loss: 1.2778\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6265 - val_loss: 0.9712\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.7552\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6216\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.5597\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6007 - val_loss: 0.5627\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 0.6231\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5910 - val_loss: 0.7336\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5866 - val_loss: 0.8894\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5825 - val_loss: 1.0844\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5786 - val_loss: 1.3149\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5750 - val_loss: 1.5741\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5716 - val_loss: 1.8621\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5684 - val_loss: 2.1733\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5654 - val_loss: 2.5019\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.6105\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.8804 - val_loss: 20.1809\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.9639 - val_loss: 10.5126\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.7520 - val_loss: 5.5578\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9802 - val_loss: 2.9813\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4818 - val_loss: 1.7500\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1604 - val_loss: 1.1261\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.8309\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8125 - val_loss: 0.7053\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7223 - val_loss: 0.6627\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6630 - val_loss: 0.6467\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6236 - val_loss: 0.6631\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5977 - val_loss: 0.6704\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5803 - val_loss: 0.6723\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - val_loss: 0.6860\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5609 - val_loss: 0.6893\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5554 - val_loss: 0.7099\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.7113\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5494 - val_loss: 0.7110\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5474 - val_loss: 0.7328\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.7332\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5372\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7972 - val_loss: 5.3623\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5243 - val_loss: 2.1669\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4246 - val_loss: 0.3850\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.3747\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3642 - val_loss: 0.3498\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3707\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3552\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3406 - val_loss: 0.4371\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3362 - val_loss: 0.3596\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.3915\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3293 - val_loss: 0.3289\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3234 - val_loss: 0.3391\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3184 - val_loss: 0.3873\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3160 - val_loss: 0.3574\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3127 - val_loss: 0.3038\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3090 - val_loss: 0.4239\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3074 - val_loss: 0.3185\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3055 - val_loss: 0.4116\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3015 - val_loss: 0.3142\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2980 - val_loss: 0.4044\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2983 - val_loss: 0.2891\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2952 - val_loss: 0.4788\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2930 - val_loss: 0.3099\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2920 - val_loss: 0.2971\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2867 - val_loss: 0.4362\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2879 - val_loss: 0.3390\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2882 - val_loss: 0.2969\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2859 - val_loss: 0.3100\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2835 - val_loss: 0.3175\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2784 - val_loss: 0.3233\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2788 - val_loss: 0.3024\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3147\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7912 - val_loss: 0.5060\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4530 - val_loss: 0.4080\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4794\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3702 - val_loss: 0.5559\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.5772\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3463 - val_loss: 0.6853\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3403 - val_loss: 0.8075\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3348 - val_loss: 0.6140\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3266 - val_loss: 0.5891\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3231 - val_loss: 0.4374\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3172 - val_loss: 0.5098\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3138 - val_loss: 0.4772\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3377\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8247 - val_loss: 0.7329\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4465 - val_loss: 0.4359\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.3665\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3760 - val_loss: 0.8860\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3708 - val_loss: 0.8751\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 1.4580\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 1.1517\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3576 - val_loss: 0.4368\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3416 - val_loss: 0.3285\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3253\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3304 - val_loss: 0.4095\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.3222\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3232 - val_loss: 0.3482\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3617\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3177 - val_loss: 0.3065\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3127 - val_loss: 0.4005\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3120 - val_loss: 0.3052\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3070 - val_loss: 0.3296\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3062 - val_loss: 0.3406\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3041 - val_loss: 0.3138\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3016 - val_loss: 0.3558\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3018 - val_loss: 0.3608\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2983 - val_loss: 0.9102\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3032 - val_loss: 0.3943\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2945 - val_loss: 0.2828\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2925 - val_loss: 0.7937\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2990 - val_loss: 0.9111\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3026 - val_loss: 0.3021\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2959 - val_loss: 0.5696\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2959 - val_loss: 0.3825\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2890 - val_loss: 0.4015\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2884 - val_loss: 0.2887\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2863 - val_loss: 0.3269\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2833 - val_loss: 0.2802\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2803 - val_loss: 0.2905\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2787 - val_loss: 0.3250\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2786 - val_loss: 0.2888\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2788 - val_loss: 0.3109\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2785 - val_loss: 0.2799\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2760 - val_loss: 0.3014\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2751 - val_loss: 0.2875\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2745 - val_loss: 0.2852\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2736 - val_loss: 0.2740\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2710 - val_loss: 0.3129\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2716 - val_loss: 0.2958\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2702 - val_loss: 0.3181\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2698 - val_loss: 0.2740\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2690 - val_loss: 0.2697\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2676 - val_loss: 0.3147\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2674 - val_loss: 0.3040\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2657 - val_loss: 0.2920\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2665 - val_loss: 0.3039\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2659 - val_loss: 0.3174\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2659 - val_loss: 0.2812\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2633 - val_loss: 0.2659\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2624 - val_loss: 0.3213\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2635 - val_loss: 0.2836\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2641 - val_loss: 0.2789\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2604 - val_loss: 0.3067\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2618 - val_loss: 0.3147\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2600 - val_loss: 0.2991\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2600 - val_loss: 0.2660\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2590 - val_loss: 0.2836\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2598 - val_loss: 0.2689\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2576 - val_loss: 0.2766\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.2870\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9441 - val_loss: 1.1754\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7715 - val_loss: 0.7800\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6912 - val_loss: 0.6516\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6469 - val_loss: 0.6242\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.5752\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5776 - val_loss: 0.5399\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5518 - val_loss: 0.5140\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 0.4992\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 0.5120\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4933 - val_loss: 0.4654\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 0.4516\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4677 - val_loss: 0.4568\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4577 - val_loss: 0.4370\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4496 - val_loss: 0.4421\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.4475\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.4328\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.4384\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.4275\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4240 - val_loss: 0.4368\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4211 - val_loss: 0.4242\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4182 - val_loss: 0.4389\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4154 - val_loss: 0.4281\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 0.4226\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4107 - val_loss: 0.4019\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.4192\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 0.4053\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4050 - val_loss: 0.4228\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.4223\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.4145\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 0.3995\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.3908\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3968 - val_loss: 0.3902\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3952 - val_loss: 0.4117\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.4173\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3927 - val_loss: 0.3834\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3911 - val_loss: 0.4190\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3900 - val_loss: 0.3730\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3887 - val_loss: 0.4248\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3875 - val_loss: 0.3794\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3865 - val_loss: 0.4065\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3853 - val_loss: 0.3899\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3752\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3834 - val_loss: 0.3737\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.4173\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.3808\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.3798\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.4118\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3868\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1903 - val_loss: 3.6358\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7645 - val_loss: 2.6147\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6781 - val_loss: 1.5796\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 1.0008\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5919 - val_loss: 0.6954\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5625 - val_loss: 0.5536\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5384 - val_loss: 0.5131\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5178 - val_loss: 0.5353\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5005 - val_loss: 0.5738\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4868 - val_loss: 0.6237\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4749 - val_loss: 0.6650\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4650 - val_loss: 0.7183\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.7327\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4503 - val_loss: 0.7027\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4441 - val_loss: 0.7028\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4388 - val_loss: 0.6691\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.6440\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4552\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9399 - val_loss: 1.5265\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8513 - val_loss: 0.7740\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7485 - val_loss: 0.7113\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6989 - val_loss: 0.6670\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6592 - val_loss: 0.6320\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6255 - val_loss: 0.5961\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 0.5668\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5708 - val_loss: 0.5437\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.5229\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 0.5035\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5116 - val_loss: 0.4857\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.4717\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4843 - val_loss: 0.4599\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.4582\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 0.4440\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.4370\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4489 - val_loss: 0.4290\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4216\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4205\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.4194\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4299 - val_loss: 0.4132\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4264 - val_loss: 0.4104\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.4075\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4202 - val_loss: 0.4197\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4177 - val_loss: 0.4045\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.4024\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.4181\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.4102\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.4292\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4080 - val_loss: 0.4200\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.4126\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4049 - val_loss: 0.4276\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.4225\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.4407\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4304\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3998 - val_loss: 0.4168\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4007\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1450 - val_loss: 20.9200\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8630 - val_loss: 7.8312\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5786 - val_loss: 0.4510\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4589 - val_loss: 0.4155\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4283 - val_loss: 0.4010\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 0.4224\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3961 - val_loss: 0.4056\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3861 - val_loss: 0.4185\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3793 - val_loss: 0.4147\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 0.4091\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3694 - val_loss: 0.3796\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3824\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.3894\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3594 - val_loss: 0.4029\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.3839\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3540 - val_loss: 0.3896\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3516 - val_loss: 0.3971\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3832\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3472 - val_loss: 0.3982\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.3793\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3443 - val_loss: 0.3825\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3429 - val_loss: 0.3701\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3409 - val_loss: 0.3696\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3403 - val_loss: 0.3449\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3381 - val_loss: 0.3712\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3370 - val_loss: 0.3453\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3364 - val_loss: 0.3601\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3348 - val_loss: 0.3793\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3326 - val_loss: 0.3650\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3450\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3307 - val_loss: 0.3526\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3297 - val_loss: 0.3338\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.3557\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3269 - val_loss: 0.3895\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3268 - val_loss: 0.3196\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3258 - val_loss: 0.3603\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3243 - val_loss: 0.3344\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3232 - val_loss: 0.3587\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.3226\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3215 - val_loss: 0.3464\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3209 - val_loss: 0.3200\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3340\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3193 - val_loss: 0.3236\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.3672\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3180 - val_loss: 0.3101\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3164 - val_loss: 0.3424\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3152 - val_loss: 0.3432\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3146 - val_loss: 0.3396\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3132 - val_loss: 0.3158\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3130 - val_loss: 0.3497\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3115 - val_loss: 0.3475\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3111 - val_loss: 0.3324\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3105 - val_loss: 0.3361\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3096 - val_loss: 0.3066\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3084 - val_loss: 0.3404\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3082 - val_loss: 0.3268\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3064 - val_loss: 0.3381\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3060 - val_loss: 0.3321\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3054 - val_loss: 0.3035\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3046 - val_loss: 0.3367\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3043 - val_loss: 0.3424\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3027 - val_loss: 0.3507\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3031 - val_loss: 0.3117\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3015 - val_loss: 0.3952\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3003 - val_loss: 0.3295\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3007 - val_loss: 0.2997\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3000 - val_loss: 0.3409\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2986 - val_loss: 0.3293\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2978 - val_loss: 0.3424\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2981 - val_loss: 0.3102\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2966 - val_loss: 0.3601\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2957 - val_loss: 0.3176\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2952 - val_loss: 0.2947\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2948 - val_loss: 0.3513\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2942 - val_loss: 0.3239\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2923 - val_loss: 0.3317\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2930 - val_loss: 0.2937\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2918 - val_loss: 0.3485\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2911 - val_loss: 0.3238\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2895 - val_loss: 0.3535\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2898 - val_loss: 0.2951\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2888 - val_loss: 0.4124\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2884 - val_loss: 0.2888\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2871 - val_loss: 0.3832\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2872 - val_loss: 0.2904\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.3594\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.3127\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2855 - val_loss: 0.3702\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2846 - val_loss: 0.2876\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2834 - val_loss: 0.3626\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2833 - val_loss: 0.2875\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2821 - val_loss: 0.3079\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2817 - val_loss: 0.2910\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2815 - val_loss: 0.2833\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2798 - val_loss: 0.2978\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2787 - val_loss: 0.3110\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2797 - val_loss: 0.3861\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2797 - val_loss: 0.2877\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2781 - val_loss: 0.5266\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2798 - val_loss: 0.4138\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3202\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1042 - val_loss: 1.4236\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6071 - val_loss: 0.5374\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5175 - val_loss: 0.7929\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4687 - val_loss: 0.9671\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4372 - val_loss: 0.8547\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4172 - val_loss: 0.5384\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.3933\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3920 - val_loss: 0.3690\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3828 - val_loss: 0.4294\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3772 - val_loss: 0.4647\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3708 - val_loss: 0.5396\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3655 - val_loss: 0.6374\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3625 - val_loss: 0.7582\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 0.8723\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.8807\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3531 - val_loss: 0.9650\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3512 - val_loss: 0.9039\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.9812\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3725\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2022 - val_loss: 14.5118\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7363 - val_loss: 9.3732\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6060 - val_loss: 3.2808\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5190 - val_loss: 0.5139\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4468 - val_loss: 0.4243\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4254 - val_loss: 0.4163\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4105 - val_loss: 0.3893\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3998 - val_loss: 0.3814\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3916 - val_loss: 0.4266\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3866 - val_loss: 0.3594\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3802 - val_loss: 0.4165\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3752 - val_loss: 0.3787\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3703 - val_loss: 0.3584\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.4034\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.3495\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3607 - val_loss: 0.3794\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3583 - val_loss: 0.3507\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3556 - val_loss: 0.3601\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.3902\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3649\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3492 - val_loss: 0.3523\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3316\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.3509\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3927\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.3263\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3364\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3377 - val_loss: 0.3669\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3366 - val_loss: 0.3250\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3361 - val_loss: 0.3797\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3344 - val_loss: 0.3454\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3314 - val_loss: 0.3556\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3703\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3292 - val_loss: 0.3872\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3282 - val_loss: 0.3272\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3267 - val_loss: 0.3192\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3247 - val_loss: 0.4152\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3636\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3253 - val_loss: 0.3960\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3231 - val_loss: 0.3124\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3216 - val_loss: 0.3703\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3199 - val_loss: 0.3526\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3190 - val_loss: 0.4162\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3193 - val_loss: 0.3423\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3182 - val_loss: 0.3497\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.3090\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3154 - val_loss: 0.3480\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3142 - val_loss: 0.3089\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3144 - val_loss: 0.3086\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3118 - val_loss: 0.3731\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3116 - val_loss: 0.3222\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3104 - val_loss: 0.4057\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3107 - val_loss: 0.3029\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3093 - val_loss: 0.3023\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3080 - val_loss: 0.3126\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3064 - val_loss: 0.3093\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3056 - val_loss: 0.3739\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3059 - val_loss: 0.3254\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3051 - val_loss: 0.2979\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3032 - val_loss: 0.3751\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3045 - val_loss: 0.3662\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3031 - val_loss: 0.3640\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3018 - val_loss: 0.2995\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3003 - val_loss: 0.3164\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3001 - val_loss: 0.3142\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2989 - val_loss: 0.3114\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2976 - val_loss: 0.3098\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2972 - val_loss: 0.3889\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2977 - val_loss: 0.4543\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3056\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3991 - val_loss: 189.8051\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6579 - val_loss: 433.5107\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.3575 - val_loss: 3086.4160\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 13.1080 - val_loss: 12429.8418\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 66.4746 - val_loss: 68042.5547\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2117.5693 - val_loss: 337128.6875\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3704.7100 - val_loss: 1710144.3750\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 49228.3164 - val_loss: 8638789.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 128870.1094 - val_loss: 43938884.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1557971.3750 - val_loss: 239176176.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3730179.7500 - val_loss: 1196082304.0000\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 3176648.2500\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9808 - val_loss: 15.9685\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 22.2275\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5099 - val_loss: 24.7966\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 22.8190\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5070 - val_loss: 22.0350\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 21.4914\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5079 - val_loss: 20.3056\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5067 - val_loss: 21.9840\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 20.2257\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 13.3590\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5060 - val_loss: 19.3508\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5033 - val_loss: 22.8717\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 24.5161\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5120 - val_loss: 13.5096\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5056 - val_loss: 17.5399\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 20.9864\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5036 - val_loss: 14.2337\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 15.2994\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 20.2001\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 14.4261\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.8726\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1829 - val_loss: 433.1348\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7067 - val_loss: 355.9439\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1537 - val_loss: 1353.2894\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 51.1187 - val_loss: 1972.5729\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.1438 - val_loss: 5291.5459\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 29.2738 - val_loss: 6130.6123\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 23.0262 - val_loss: 9387.7891\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 242.1741 - val_loss: 13434.7920\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 108.5372 - val_loss: 19358.6406\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 21.2470 - val_loss: 22282.9336\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 979.4358 - val_loss: 30182.8555\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 119.7463 - val_loss: 40083.0234\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 42.7416\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.3731 - val_loss: 2.2260\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8418 - val_loss: 0.9684\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7132 - val_loss: 0.7262\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6647 - val_loss: 0.6337\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6320 - val_loss: 0.5967\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6059 - val_loss: 0.5708\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5837 - val_loss: 0.5492\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5644 - val_loss: 0.5300\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5470 - val_loss: 0.5131\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5310 - val_loss: 0.4978\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5164 - val_loss: 0.4844\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5029 - val_loss: 0.4716\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4907 - val_loss: 0.4599\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4796 - val_loss: 0.4518\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4694 - val_loss: 0.4410\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4600 - val_loss: 0.4340\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4518 - val_loss: 0.4270\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4442 - val_loss: 0.4198\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4369 - val_loss: 0.4186\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4310 - val_loss: 0.4090\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4252 - val_loss: 0.4120\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4200 - val_loss: 0.4019\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 0.3995\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4109 - val_loss: 0.3922\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4072 - val_loss: 0.3951\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4037 - val_loss: 0.3906\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.3893\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3972 - val_loss: 0.3932\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3941 - val_loss: 0.3936\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3918 - val_loss: 0.3854\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3891 - val_loss: 0.3760\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.3751\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.3805\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.3819\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3809 - val_loss: 0.3703\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.3795\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.3653\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3757 - val_loss: 0.3803\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.3638\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3727 - val_loss: 0.3757\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3712 - val_loss: 0.3700\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3698 - val_loss: 0.3639\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.3607\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3769\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.3675\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3651 - val_loss: 0.3665\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3642 - val_loss: 0.3770\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3750\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3620 - val_loss: 0.3711\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3812\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.3812\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3790\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3804\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3759\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.1670 - val_loss: 2.3397\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0201 - val_loss: 2.1449\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7559 - val_loss: 1.3417\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6689 - val_loss: 0.9187\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6278 - val_loss: 0.6837\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5998 - val_loss: 0.5753\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5761 - val_loss: 0.5331\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5546 - val_loss: 0.5386\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5352 - val_loss: 0.5579\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5179 - val_loss: 0.5921\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5021 - val_loss: 0.6440\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4883 - val_loss: 0.7317\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4766 - val_loss: 0.7848\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4662 - val_loss: 0.7787\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4570 - val_loss: 0.8254\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4489 - val_loss: 0.8191\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4417 - val_loss: 0.8210\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4528\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.9114 - val_loss: 1.7769\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0183 - val_loss: 0.8237\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7536 - val_loss: 0.6985\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6861 - val_loss: 0.6926\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6516 - val_loss: 0.6085\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6247 - val_loss: 0.5847\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6018 - val_loss: 0.5633\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5823 - val_loss: 0.5646\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5653 - val_loss: 0.5214\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5485 - val_loss: 0.5078\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5322 - val_loss: 0.4900\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5177 - val_loss: 0.4795\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5038 - val_loss: 0.4702\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4912 - val_loss: 0.4684\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4793 - val_loss: 0.4555\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4687 - val_loss: 0.4367\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4589 - val_loss: 0.4357\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4500 - val_loss: 0.4332\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4424 - val_loss: 0.4303\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4350 - val_loss: 0.4211\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4287 - val_loss: 0.4202\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4232 - val_loss: 0.4160\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.4226\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4129 - val_loss: 0.4539\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4092 - val_loss: 0.4101\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4051\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4018 - val_loss: 0.4311\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3988 - val_loss: 0.4356\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.4534\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3936 - val_loss: 0.4189\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3906 - val_loss: 0.3936\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3884 - val_loss: 0.4379\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3860 - val_loss: 0.4061\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3842 - val_loss: 0.4712\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.4154\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3804 - val_loss: 0.3879\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3792 - val_loss: 0.3907\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3771 - val_loss: 0.4342\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3758 - val_loss: 0.3813\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.3885\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.4557\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3716 - val_loss: 0.4233\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3696 - val_loss: 0.3577\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.4079\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.3947\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3666 - val_loss: 0.4023\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3653 - val_loss: 0.3488\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.3575\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.4377\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.4032\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3612 - val_loss: 0.3950\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3605 - val_loss: 0.3924\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3597 - val_loss: 0.3671\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.3502\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3576 - val_loss: 0.3543\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.3628\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3559 - val_loss: 0.3855\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3557\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6095 - val_loss: 0.3877\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.8544\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3948 - val_loss: 0.3452\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3664 - val_loss: 2.1781\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 6.0431\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4581 - val_loss: 0.4473\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3643 - val_loss: 0.4401\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3539 - val_loss: 1.3479\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 2.6715\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3667 - val_loss: 0.3289\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 6.3833\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3967 - val_loss: 0.8227\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3455\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3151\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3283 - val_loss: 0.3308\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3246 - val_loss: 0.3125\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3206 - val_loss: 0.3724\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3182 - val_loss: 0.3174\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3158 - val_loss: 0.3061\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3134 - val_loss: 0.3780\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3096 - val_loss: 0.3157\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3062 - val_loss: 0.3538\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3046 - val_loss: 0.3118\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3020 - val_loss: 0.4392\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3010\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2961 - val_loss: 0.4209\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2946 - val_loss: 0.3316\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2937 - val_loss: 0.4017\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2909 - val_loss: 0.3008\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2899 - val_loss: 0.3310\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2884 - val_loss: 0.3077\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2853 - val_loss: 0.3624\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2832 - val_loss: 0.2797\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2806 - val_loss: 0.2967\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2792 - val_loss: 0.3538\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2787 - val_loss: 0.2894\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2765 - val_loss: 0.5177\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2755 - val_loss: 0.3499\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2751 - val_loss: 0.4183\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2738 - val_loss: 0.2758\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2725 - val_loss: 0.3525\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2729 - val_loss: 0.2722\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2672 - val_loss: 0.4103\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2677 - val_loss: 0.2940\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2654 - val_loss: 0.2676\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2668 - val_loss: 0.3012\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2653 - val_loss: 0.4097\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2648 - val_loss: 0.2723\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2643 - val_loss: 0.2747\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2618 - val_loss: 0.2629\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2613 - val_loss: 0.4552\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2637 - val_loss: 0.8182\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2683 - val_loss: 0.6077\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2636 - val_loss: 0.2700\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2606 - val_loss: 0.2976\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2596 - val_loss: 0.3053\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2580 - val_loss: 0.2991\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2567 - val_loss: 0.3343\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2571 - val_loss: 0.3089\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2558 - val_loss: 0.2615\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2529 - val_loss: 0.3033\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2541 - val_loss: 0.3367\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2539 - val_loss: 0.2654\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2554 - val_loss: 0.2632\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2516 - val_loss: 0.2670\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2515 - val_loss: 0.2654\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2515 - val_loss: 0.2615\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2488 - val_loss: 0.2719\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2507 - val_loss: 0.2676\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2486 - val_loss: 0.3187\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2478 - val_loss: 0.3171\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2478 - val_loss: 0.2694\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2489 - val_loss: 0.2670\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2490 - val_loss: 0.3233\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2468 - val_loss: 0.3080\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2455 - val_loss: 0.2943\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2443 - val_loss: 0.4364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000021CCC433610>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021CCC52D1C0>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100, \n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.012893679787405549, 'n_hidden': 3, 'n_neurons': 45}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3131283422311147"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.save(\"rnd_search_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_new)\n",
    "plt.plot(y_test[:3], 'r-')\n",
    "plt.plot(y_pred, 'g-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Finance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efff15bf12be43539ce966637c191450e39a8dc1731466863e37e46446fa5e0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
